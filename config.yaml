################################################################################
# FEW-SHOT AUDIO EVAL CONFIGURATION FILE
################################################################################

#########################
# BASE SETTINGS
#########################
base:
  seed: 42
  num_workers: 0
  cuda: True

  path_to_configs: 'dataset_/configs_'
  results_path: #'sample_results.csv' #argparse


#########################
# MODEL/ENCODER
#########################
model:
  model_dir: #X:/Trained_model_storage/MT-SLVR Large Work/RN18 Main Models Extracted/none #argparse
  name: #resnet18 #resnet18/ast_tiny etc Prefix are added to the model depending on what adapter is selected #argparse
  dims: #2 #argparse
  in_channels: #3 #argparse
  input_tdim:  # Only needed for ast models # Now auto compute 
  encoder_fc_dim: #1000 #argparse

adapters:
  #task_mode: None # series_adapters/parallel_adapters/bn/split for resnets #argparse
              # adaptformer_series/adaptformer_parallel/og_adapter for asts

  num_splits: #1 # Number of splits in the fc layer in backbone #argparse


#########################
# FEATURE EXTRACTION
#########################
extraction:
  batch_size: 1 # Has to stay at 1 (allows for variable sets to be processed correctly)
  num_workers: 0

#########################
# FEW-SHOT TASKS
#########################
task:
  n_way: #5 #argparse
  k_shot: #1 #argparse
  q_queries: #1 #argparse
  num_tasks: #10000 #argparse
  batch_size: 1 # Batch size best kept to 1 when including any variable length set
  split: #val # test/val #argparse
  hardness: [avg] # Task hardnesses to consider

#########################
# CLASSIFIER
#########################
classifier:
  type: #sklin #linear/NCC/sklin
  adapt_steps: 20
  lr: 0.01


#########################
# DATA
#########################
data:
  source_dataset: FSD50K
  norm: sample #sample/global/None/l2 # We use per-sample wise stats by default
  stats_file: dataset_/stats_/FSD50k_train_stats.npy
  ext: '.npy'

  # Input dimensionality of data: Has to match what model expects
  in_dims: 2
  in_channels: 3


# All absolute paths to datasets of interest
data_paths:
  ESC: 'X:/Datasets/ESC-50-master/Sorted_npy'
  Kaggle18_5s: X:/Datasets/Kaggle AudioSet/Raw_5_second_npy
  NSYNTH: 'X:/Datasets/NSynth/nsynth_npy_no_norm'
  VoxCeleb_5s: 'X:/Datasets/VoxCeleb1/voxceleb_5s_raw'
  BirdClef_5s: 'X:/Datasets/Rw Datasets/BirdClef_npy_pruned_5s_raw'

  Watkins_5s: 'X:/Datasets/Wakins/watkins_5s_raw_npy'
  SCV2_1s: 'X:/Datasets/Speech Commands/V2/SCV2_1s_raw_npy'

  SAA_5s: X:/Datasets/Speech Accent Archive/sorted_recordings_5s_raw
  CommonVoice_5s: X:/Datasets/Common_Voice/reduced_raw_5s
  CremaD_5s: X:/Datasets/CremaD/sorted_5s_raw


# Whether to precompute features or to use raw data sampling. Speed benefit is highly dependant on dataset size
use_feats:
  ESC: True
  Kaggle18_5s: True
  NSYNTH: False
  VoxCeleb_5s: False
  BirdClef_5s: True

  Watkins_5s: True
  SCV2_1s: False

  SAA_5s: True
  CommonVoice_5s: False
  CremaD_5s: True


# Fourier transform params
ft_params:
  sample_rate: 16000
  n_mels: 128
  n_fft: 1024
  hop_length: 512
  power: 2
